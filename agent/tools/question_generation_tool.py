"""
Question Generation Tool for ALQ-Agent
=====================================

Generates personalized questions using retrieved contexts, templates, and student profiles.
Integrates with LLM services to create educationally sound questions.
"""

import sys
import os
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import json
import logging
import random
import re

# Add the project root to the path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

try:
    from .prompts.generation_prompts import GenerationPrompts
except ImportError:
    try:
        from agent.prompts.generation_prompts import GenerationPrompts
    except ImportError:
        GenerationPrompts = None


@dataclass
class StudentProfile:
    """Student profile for question generation."""
    grade: int
    subject: str
    skill: str
    skill_name: str
    low_accuracy_skills: List[str]
    slow_response_skills: List[str]
    difficulty_preference: str = "medium"
    learning_style: Optional[str] = None


@dataclass
class GeneratedQuestion:
    """Generated question structure."""
    grade: int
    skill: str
    skill_name: str
    subject: str
    question: str
    image_question: str
    answers: List[Dict[str, Any]]
    image_answer: str
    explanation: str
    difficulty: str
    template_used: str
    generation_metadata: Dict[str, Any]


class QuestionGenerationTool:
    """
    Question Generation Tool for creating personalized questions.
    
    This tool synthesizes retrieved contexts, templates, and student profiles
    to generate educationally appropriate questions using LLM services.
    """
    
    def __init__(self, 
                 llm_connector: Optional[Any] = None,
                 verbose: bool = True):
        """
        Initialize the Question Generation Tool.
        
        Args:
            llm_connector: LLM connector instance
            verbose: Enable verbose logging
        """
        self.verbose = verbose
        self.llm_connector = llm_connector or self._create_mock_llm()
        
        if self.verbose:
            print("‚úèÔ∏è Question Generation Tool initialized")
    
    def _create_mock_llm(self) -> Any:
        """Create mock LLM connector for development."""
        return MockLLMConnector()
    
    def generate(self, 
                topic: str,
                teacher_context: List[Dict[str, Any]],
                textbook_context: List[Dict[str, Any]],
                template: Any,
                student_profile: StudentProfile) -> GeneratedQuestion:
        """
        Generate a personalized question based on contexts and template.
        
        Args:
            topic: Topic or skill to generate question for
            teacher_context: Pedagogical context from teacher_book
            textbook_context: Content context from textbook
            template: Question template to use
            student_profile: Student profile information
            
        Returns:
            GeneratedQuestion instance
        """
        if self.verbose:
            print(f"üéØ Generating question for topic: {topic}")
            print(f"   Grade: {student_profile.grade}")
            print(f"   Skill: {student_profile.skill}")
            print(f"   Template: {template.type.value if hasattr(template, 'type') else 'unknown'}")
        
        try:
            # Prepare context for generation
            context_data = self._prepare_context_data(
                teacher_context, textbook_context, student_profile
            )
            
            # Generate question based on template type
            if hasattr(template, 'type'):
                if template.type.value == "multiple_choice":
                    question_data = self._generate_multiple_choice(
                        topic, template, context_data, student_profile
                    )
                elif template.type.value == "true_false":
                    question_data = self._generate_true_false(
                        topic, template, context_data, student_profile
                    )
                elif template.type.value == "fill_in_blank":
                    question_data = self._generate_fill_in_blank(
                        topic, template, context_data, student_profile
                    )
                else:
                    # Default to multiple choice
                    question_data = self._generate_multiple_choice(
                        topic, template, context_data, student_profile
                    )
            else:
                # Fallback to basic generation
                question_data = self._generate_basic_question(
                    topic, context_data, student_profile
                )
            
            # Create GeneratedQuestion object
            generated_question = GeneratedQuestion(
                grade=student_profile.grade,
                skill=student_profile.skill,
                skill_name=student_profile.skill_name,
                subject=student_profile.subject,
                question=question_data['question'],
                image_question=question_data.get('image_question', ''),
                answers=question_data['answers'],
                image_answer=question_data.get('image_answer', ''),
                explanation=question_data.get('explanation', ''),
                difficulty=question_data.get('difficulty', student_profile.difficulty_preference),
                template_used=template.type.value if hasattr(template, 'type') else 'unknown',
                generation_metadata={
                    'teacher_context_count': len(teacher_context),
                    'textbook_context_count': len(textbook_context),
                    'generation_method': 'llm_synthesis'
                }
            )
            
            if self.verbose:
                print(f"‚úÖ Question generated successfully")
                print(f"   Question: {generated_question.question[:50]}...")
                print(f"   Answers: {len(generated_question.answers)}")
            
            return generated_question
            
        except Exception as e:
            if self.verbose:
                print(f"‚ùå Question generation failed: {e}")
            
            # Return fallback question
            return self._create_fallback_question(topic, student_profile)
    
    def _prepare_context_data(self, 
                             teacher_context: List[Dict[str, Any]],
                             textbook_context: List[Dict[str, Any]],
                             student_profile: StudentProfile) -> Dict[str, Any]:
        """Prepare context data for question generation."""
        # Extract relevant content from contexts
        teacher_content = []
        for ctx in teacher_context:
            content = ctx.get('content', '')
            if content:
                teacher_content.append(content)
        
        textbook_content = []
        for ctx in textbook_context:
            content = ctx.get('content', '')
            if content:
                textbook_content.append(content)
        
        return {
            'teacher_guidance': teacher_content,
            'textbook_examples': textbook_content,
            'student_grade': student_profile.grade,
            'subject': student_profile.subject,
            'skill': student_profile.skill,
            'skill_name': student_profile.skill_name
        }
    
    def _generate_multiple_choice(self, 
                                 topic: str,
                                 template: Any,
                                 context_data: Dict[str, Any],
                                 student_profile: StudentProfile) -> Dict[str, Any]:
        """Generate multiple choice question."""
        # Use LLM to generate question content
        prompt = self._create_generation_prompt(topic, template, context_data, "multiple_choice")
        
        # Generate using LLM
        llm_response = self.llm_connector.generate(prompt)
        
        # Parse LLM response
        question_data = self._parse_llm_response(llm_response, "multiple_choice")
        
        # Ensure we have the required structure
        if 'answers' not in question_data:
            question_data['answers'] = self._generate_fallback_answers(topic, student_profile)
        
        # Ensure exactly 4 answers
        answers = question_data['answers']
        if len(answers) != 4:
            answers = self._adjust_answer_count(answers, 4)
        
        question_data['answers'] = answers
        return question_data
    
    def _generate_true_false(self, 
                            topic: str,
                            template: Any,
                            context_data: Dict[str, Any],
                            student_profile: StudentProfile) -> Dict[str, Any]:
        """Generate true/false question."""
        prompt = self._create_generation_prompt(topic, template, context_data, "true_false")
        llm_response = self.llm_connector.generate(prompt)
        question_data = self._parse_llm_response(llm_response, "true_false")
        
        # Ensure we have exactly 2 answers for true/false
        if 'answers' not in question_data or len(question_data['answers']) != 2:
            question_data['answers'] = [
                {"text": "ƒê√∫ng", "correct": True},
                {"text": "Sai", "correct": False}
            ]
        
        return question_data
    
    def _generate_fill_in_blank(self, 
                               topic: str,
                               template: Any,
                               context_data: Dict[str, Any],
                               student_profile: StudentProfile) -> Dict[str, Any]:
        """Generate fill-in-the-blank question."""
        prompt = self._create_generation_prompt(topic, template, context_data, "fill_in_blank")
        llm_response = self.llm_connector.generate(prompt)
        question_data = self._parse_llm_response(llm_response, "fill_in_blank")
        
        # Ensure we have 4 answer options
        if 'answers' not in question_data:
            question_data['answers'] = self._generate_fallback_answers(topic, student_profile)
        
        answers = question_data['answers']
        if len(answers) != 4:
            answers = self._adjust_answer_count(answers, 4)
        
        question_data['answers'] = answers
        return question_data
    
    def _generate_basic_question(self, 
                               topic: str,
                               context_data: Dict[str, Any],
                               student_profile: StudentProfile) -> Dict[str, Any]:
        """Generate basic question as fallback."""
        # Create a simple question based on the topic
        question = f"B√†i t·∫≠p v·ªÅ {topic} cho h·ªçc sinh l·ªõp {student_profile.grade}"
        
        # Generate simple answers
        answers = self._generate_fallback_answers(topic, student_profile)
        
        return {
            'question': question,
            'answers': answers,
            'explanation': f"ƒê√¢y l√† c√¢u h·ªèi v·ªÅ {topic} d√†nh cho h·ªçc sinh l·ªõp {student_profile.grade}",
            'difficulty': student_profile.difficulty_preference
        }
    
    def _create_generation_prompt(self, 
                                 topic: str,
                                 template: Any,
                                 context_data: Dict[str, Any],
                                 question_type: str) -> str:
        """Create prompt for LLM generation using prompts module."""
        if GenerationPrompts:
            # Use prompts from prompts module
            if question_type == "multiple_choice":
                return GenerationPrompts.multiple_choice_generation(
                    topic=topic,
                    grade=context_data['student_grade'],
                    subject=context_data['subject'],
                    teacher_context=context_data['teacher_guidance'],
                    textbook_context=context_data['textbook_examples']
                )
            elif question_type == "true_false":
                return GenerationPrompts.true_false_generation(
                    topic=topic,
                    grade=context_data['student_grade'],
                    subject=context_data['subject'],
                    teacher_context=context_data['teacher_guidance'],
                    textbook_context=context_data['textbook_examples']
                )
            elif question_type == "fill_in_blank":
                return GenerationPrompts.fill_in_blank_generation(
                    topic=topic,
                    grade=context_data['student_grade'],
                    subject=context_data['subject'],
                    teacher_context=context_data['teacher_guidance'],
                    textbook_context=context_data['textbook_examples']
                )
            elif context_data['subject'].lower() in ['to√°n', 'math']:
                return GenerationPrompts.math_specific_generation(
                    topic=topic,
                    grade=context_data['student_grade'],
                    skill=context_data['skill'],
                    teacher_context=context_data['teacher_guidance'],
                    textbook_context=context_data['textbook_examples']
                )
            elif context_data['subject'].lower() in ['ti·∫øng vi·ªát', 'vietnamese']:
                return GenerationPrompts.language_specific_generation(
                    topic=topic,
                    grade=context_data['student_grade'],
                    skill=context_data['skill'],
                    teacher_context=context_data['teacher_guidance'],
                    textbook_context=context_data['textbook_examples']
                )
        
        # Fallback to original prompt if prompts module not available
        prompt = f"""
T·∫°o c√¢u h·ªèi {question_type} cho h·ªçc sinh l·ªõp {context_data['student_grade']} v·ªÅ ch·ªß ƒë·ªÅ: {topic}

Th√¥ng tin h·ªçc sinh:
- L·ªõp: {context_data['student_grade']}
- M√¥n h·ªçc: {context_data['subject']}
- K·ªπ nƒÉng: {context_data['skill_name']} ({context_data['skill']})

H∆∞·ªõng d·∫´n t·ª´ gi√°o vi√™n:
{chr(10).join(context_data['teacher_guidance'][:3])}

V√≠ d·ª• t·ª´ s√°ch gi√°o khoa:
{chr(10).join(context_data['textbook_examples'][:3])}

Y√™u c·∫ßu:
1. T·∫°o c√¢u h·ªèi ph√π h·ª£p v·ªõi tr√¨nh ƒë·ªô l·ªõp {context_data['student_grade']}
2. S·ª≠ d·ª•ng ng√¥n ng·ªØ ƒë∆°n gi·∫£n, d·ªÖ hi·ªÉu
3. T·∫°o 4 ƒë√°p √°n cho c√¢u h·ªèi tr·∫Øc nghi·ªám
4. ƒê·∫£m b·∫£o ch·ªâ c√≥ 1 ƒë√°p √°n ƒë√∫ng
5. Th√™m gi·∫£i th√≠ch ng·∫Øn g·ªçn

ƒê·ªãnh d·∫°ng JSON:
{{
    "question": "C√¢u h·ªèi...",
    "answers": [
        {{"text": "ƒê√°p √°n 1", "correct": true}},
        {{"text": "ƒê√°p √°n 2", "correct": false}},
        {{"text": "ƒê√°p √°n 3", "correct": false}},
        {{"text": "ƒê√°p √°n 4", "correct": false}}
    ],
    "explanation": "Gi·∫£i th√≠ch..."
}}
"""
        return prompt
    
    def _parse_llm_response(self, response: str, question_type: str) -> Dict[str, Any]:
        """Parse LLM response into question data."""
        try:
            # Try to extract JSON from response
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                return json.loads(json_str)
        except (json.JSONDecodeError, AttributeError):
            pass
        
        # Fallback parsing
        return {
            'question': response[:200] + "..." if len(response) > 200 else response,
            'answers': [],
            'explanation': "C√¢u h·ªèi ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông"
        }
    
    def _generate_fallback_answers(self, topic: str, student_profile: StudentProfile) -> List[Dict[str, Any]]:
        """Generate fallback answers when LLM fails."""
        # Simple fallback based on topic
        if "c·ªông" in topic.lower() or "addition" in topic.lower():
            return [
                {"text": "5", "correct": True},
                {"text": "4", "correct": False},
                {"text": "6", "correct": False},
                {"text": "3", "correct": False}
            ]
        elif "tr·ª´" in topic.lower() or "subtraction" in topic.lower():
            return [
                {"text": "3", "correct": True},
                {"text": "2", "correct": False},
                {"text": "4", "correct": False},
                {"text": "1", "correct": False}
            ]
        else:
            return [
                {"text": "ƒê√°p √°n A", "correct": True},
                {"text": "ƒê√°p √°n B", "correct": False},
                {"text": "ƒê√°p √°n C", "correct": False},
                {"text": "ƒê√°p √°n D", "correct": False}
            ]
    
    def _adjust_answer_count(self, answers: List[Dict[str, Any]], target_count: int) -> List[Dict[str, Any]]:
        """Adjust answer count to target number."""
        if len(answers) == target_count:
            return answers
        
        if len(answers) > target_count:
            # Keep first target_count answers
            return answers[:target_count]
        else:
            # Add more answers to reach target_count
            while len(answers) < target_count:
                answers.append({
                    "text": f"ƒê√°p √°n {chr(65 + len(answers))}",
                    "correct": False
                })
            return answers
    
    def _create_fallback_question(self, topic: str, student_profile: StudentProfile) -> GeneratedQuestion:
        """Create fallback question when generation fails."""
        return GeneratedQuestion(
            grade=student_profile.grade,
            skill=student_profile.skill,
            skill_name=student_profile.skill_name,
            subject=student_profile.subject,
            question=f"B√†i t·∫≠p v·ªÅ {topic} cho h·ªçc sinh l·ªõp {student_profile.grade}",
            image_question="",
            answers=self._generate_fallback_answers(topic, student_profile),
            image_answer="",
            explanation=f"ƒê√¢y l√† c√¢u h·ªèi m·∫´u v·ªÅ {topic}",
            difficulty=student_profile.difficulty_preference,
            template_used="fallback",
            generation_metadata={
                'teacher_context_count': 0,
                'textbook_context_count': 0,
                'generation_method': 'fallback'
            }
        )


class MockLLMConnector:
    """Mock LLM connector for development and testing."""
    
    def __init__(self):
        self.verbose = True
    
    def generate(self, prompt: str) -> str:
        """Mock LLM generation."""
        # Extract topic from prompt
        topic_match = re.search(r'ch·ªß ƒë·ªÅ: (.+?)\n', prompt)
        topic = topic_match.group(1) if topic_match else "to√°n h·ªçc"
        
        # Generate mock response based on topic
        if "c·ªông" in topic.lower() or "addition" in topic.lower():
            return """
{
    "question": "2 + 3 = ?",
    "answers": [
        {"text": "5", "correct": true},
        {"text": "4", "correct": false},
        {"text": "6", "correct": false},
        {"text": "7", "correct": false}
    ],
    "explanation": "2 c·ªông 3 b·∫±ng 5 theo ph√©p c·ªông c∆° b·∫£n."
}
"""
        elif "tr·ª´" in topic.lower() or "subtraction" in topic.lower():
            return """
{
    "question": "5 - 2 = ?",
    "answers": [
        {"text": "3", "correct": true},
        {"text": "2", "correct": false},
        {"text": "4", "correct": false},
        {"text": "1", "correct": false}
    ],
    "explanation": "5 tr·ª´ 2 b·∫±ng 3 theo ph√©p tr·ª´ c∆° b·∫£n."
}
"""
        else:
            return """
{
    "question": "C√¢u h·ªèi m·∫´u v·ªÅ " + topic,
    "answers": [
        {"text": "ƒê√°p √°n A", "correct": true},
        {"text": "ƒê√°p √°n B", "correct": false},
        {"text": "ƒê√°p √°n C", "correct": false},
        {"text": "ƒê√°p √°n D", "correct": false}
    ],
    "explanation": "ƒê√¢y l√† c√¢u h·ªèi m·∫´u."
}
"""


# Convenience functions
def create_question_generation_tool(llm_connector: Optional[Any] = None,
                                   verbose: bool = True) -> QuestionGenerationTool:
    """
    Create a QuestionGenerationTool instance.
    
    Args:
        llm_connector: Optional LLM connector instance
        verbose: Enable verbose logging
        
    Returns:
        QuestionGenerationTool instance
    """
    return QuestionGenerationTool(
        llm_connector=llm_connector,
        verbose=verbose
    )


# Testing and validation
if __name__ == "__main__":
    print("üß™ Testing Question Generation Tool")
    print("=" * 50)
    
    try:
        # Create generation tool
        print("\nüìù Creating question generation tool...")
        generation_tool = QuestionGenerationTool(verbose=True)
        
        # Create test student profile
        student_profile = StudentProfile(
            grade=1,
            subject="To√°n",
            skill="S5",
            skill_name="M·∫•y v√† m·∫•y",
            low_accuracy_skills=["S5"],
            slow_response_skills=[],
            difficulty_preference="easy"
        )
        
        # Create test contexts
        teacher_context = [
            {"content": "H∆∞·ªõng d·∫´n d·∫°y ph√©p c·ªông cho h·ªçc sinh l·ªõp 1"},
            {"content": "S·ª≠ d·ª•ng ƒë·ªì v·∫≠t ƒë·ªÉ minh h·ªça ph√©p c·ªông"}
        ]
        
        textbook_context = [
            {"content": "2 + 3 = 5"},
            {"content": "B√†i t·∫≠p: 1 + 4 = ?"}
        ]
        
        # Create test template
        from agent.tools.template_tool import QuestionTemplate, QuestionType, DifficultyLevel
        template = QuestionTemplate(
            type=QuestionType.MULTIPLE_CHOICE,
            pattern="{a} + {b} = ?",
            options_count=4,
            grade_range=(1, 2),
            subjects=["To√°n"],
            difficulty=DifficultyLevel.EASY,
            description="Basic addition for Grade 1",
            example={}
        )
        
        # Test 1: Generate multiple choice question
        print(f"\nüß™ Test 1: Generate multiple choice question")
        question = generation_tool.generate(
            topic="ph√©p c·ªông",
            teacher_context=teacher_context,
            textbook_context=textbook_context,
            template=template,
            student_profile=student_profile
        )
        
        print(f"‚úÖ Generated question:")
        print(f"   Question: {question.question}")
        print(f"   Answers: {len(question.answers)}")
        print(f"   Difficulty: {question.difficulty}")
        print(f"   Template: {question.template_used}")
        
        # Test 2: Generate with different template
        print(f"\nüß™ Test 2: Generate true/false question")
        tf_template = QuestionTemplate(
            type=QuestionType.TRUE_FALSE,
            pattern="{statement}",
            options_count=2,
            grade_range=(1, 2),
            subjects=["To√°n"],
            difficulty=DifficultyLevel.EASY,
            description="True/False for Grade 1",
            example={}
        )
        
        tf_question = generation_tool.generate(
            topic="ph√©p c·ªông",
            teacher_context=teacher_context,
            textbook_context=textbook_context,
            template=tf_template,
            student_profile=student_profile
        )
        
        print(f"‚úÖ Generated T/F question:")
        print(f"   Question: {tf_question.question}")
        print(f"   Answers: {len(tf_question.answers)}")
        
        print(f"\nüéâ All question generation tests completed successfully!")
        
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        import traceback
        traceback.print_exc()
