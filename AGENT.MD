# üß† Adaptive Learning Question Agent (ALQ-Agent)

## üìò Overview

The **Adaptive Learning Question Agent (ALQ-Agent)** is a core intelligence module within the Mini adaptive learning system.  
Its role is to **generate, validate, and refine personalized practice questions** for each student, using official learning materials and pedagogy guidance.

The agent operates through four specialized tools located in the `/agent/tools` module:
1. **RAGTool** ‚Äî Retrieves structured knowledge from `teacher_book` and `textbook` vector databases.  
2. **TemplateTool** ‚Äî Supplies predefined question structures and formats.  
3. **QuestionGenerationTool** ‚Äî Synthesizes retrieved content and templates to generate new questions.  
4. **ValidationTool** ‚Äî Ensures the question‚Äôs accuracy, difficulty, and educational soundness.

---

## üéØ Mission

> ‚ÄúTo create meaningful, personalized questions that help students strengthen their weak skills while aligning with approved curriculum and pedagogical methods.‚Äù

The ALQ-Agent generates **adaptive learning questions** using both:
- **Teacher Book (sgv_collection)** ‚Äî guidance for teachers on how to teach, explain, and scaffold a concept.  
- **Textbook (baitap_collection)** ‚Äî exercises, examples, and illustrations for student-facing content.

---

## üìÇ Folder Structure

```

/agent
‚îÇ
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ rag_tool.py
‚îÇ   ‚îú‚îÄ‚îÄ template_tool.py
‚îÇ   ‚îú‚îÄ‚îÄ question_generation_tool.py
‚îÇ   ‚îî‚îÄ‚îÄ validation_tool.py
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ llm_connector.py
‚îÇ   ‚îú‚îÄ‚îÄ embedding_model.py  # Wrapper for database/embeddings/local_embedder.py
‚îÇ   ‚îî‚îÄ‚îÄ model_router.py
‚îÇ
‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îú‚îÄ‚îÄ system_prompt.txt
‚îÇ   ‚îú‚îÄ‚îÄ generation_prompt.txt
‚îÇ   ‚îú‚îÄ‚îÄ validation_prompt.txt
‚îÇ   ‚îî‚îÄ‚îÄ template_prompt.txt
‚îÇ
‚îî‚îÄ‚îÄ workflow/
‚îú‚îÄ‚îÄ agent_workflow.py
‚îú‚îÄ‚îÄ utils.py
‚îî‚îÄ‚îÄ state_schema.py

````

---

## üß© Workflow Behavior

### Step 1: Understand the Context
The agent begins by analyzing the input payload:
- `grade`: student‚Äôs grade level.  
- `low_accuracy_skills`: skills with low test performance.  
- `slow_response_skills`: skills where student response time is slow.  
- `subject`: subject and topic (e.g., ‚ÄúTo√°n 1: Nhi·ªÅu h∆°n, √≠t h∆°n, b·∫±ng nhau‚Äù).  

The agent identifies the **core skill** and determines what kind of question will best strengthen that area.

---

### Step 2: Retrieve Dual Knowledge Context

**Tool:** `RAGTool`

The agent queries two separate vector databases (in Milvus):
- `sgv_collection` ‚Üí **teacher_book**
  - Pedagogical strategies, conceptual explanations, and methods of teaching.
- `baitap_collection` ‚Üí **textbook**
  - Concrete examples, student exercises, and illustrations.

**Output:**
```python
{
  "teacher_context": [ "how to introduce subtraction with borrowing", ... ],
  "textbook_context": [ "worked examples of 13 - 7", ... ]
}
````

---

### Step 3: Select a Suitable Question Template

**Tool:** `TemplateTool`

The agent selects an appropriate structure for the question, based on:

* Subject (e.g., Math)
* Grade
* Difficulty (derived from student profile)

**Examples:**

* Multiple Choice
* True/False with explanation
* Fill in the blank (with 4 answer options)

**Output Example:**

```python
{
  "type": "multiple_choice",
  "pattern": "{a} + {b} = ?",
  "options": 4
}
```

---

### Step 4: Generate the Question

**Tool:** `QuestionGenerationTool`

The agent calls this tool with:

* `teacher_context`
* `textbook_context`
* `template`
* `student_profile`

The tool uses the LLM (e.g., OpenAI, Claude, or SAINT) to synthesize a question consistent with both content and pedagogy.

**Requirements:**

* Use examples from `textbook_context`
* Follow explanation style from `teacher_context`
* Ensure question language fits grade level

**Output Example:**

```json
{
  "grade": 1,
  "skill": "S5",
  "skill_name": "M·∫•y v√† m·∫•y",
  "subject": "To√°n",
  "question": "2 + 3 = m·∫•y?",
  "answers": [
    {"text": "5", "correct": true},
    {"text": "4", "correct": false},
    {"text": "6", "correct": false},
    {"text": "7", "correct": false}
  ],
  "difficulty": "medium",
  "explaination": "2 c·ªông 3 b·∫±ng 5 theo ph√©p c·ªông c∆° b·∫£n."
}
```

---

### Step 5: Validate Before Finalizing

**Tool:** `ValidationTool`

Ensures the question meets the following standards:

* ‚úÖ **Accuracy:** Matches mathematical or factual correctness.
* üéØ **Difficulty:** Aligns with the target grade.
* üìö **Clarity:** Uses age-appropriate language and follows teacher guidance.
* üßë‚Äçüè´ **Pedagogical alignment:** Complies with methods from `teacher_book`.

If validation fails:

* Regenerate the question up to **2 times**.
* Return `"validation_status": "approved"` only after passing checks.

**Validation Output:**

```json
{
  "valid": true,
  "validation_status": "approved",
  "feedback": "Question is accurate and grade-appropriate."
}
```

---

### Step 6: Return Final Structured Result

Final response schema:

```json
{
  "grade": 1,
  "skill": "S5",
  "skill_name": "M·∫•y v√† m·∫•y",
  "subject": "To√°n",
  "question": "2 + 3 = m·∫•y?",
  "image_question": "",
  "answers": [
    {"text": "5", "correct": true},
    {"text": "4", "correct": false},
    {"text": "6", "correct": false},
    {"text": "7", "correct": false}
  ],
  "image_answer": "",
  "explaination": "2 c·ªông 3 b·∫±ng 5 theo ph√©p c·ªông c∆° b·∫£n.",
  "difficulty": "medium",
  "validation_status": "approved"
}
```

---

## üß† Tool Specifications

### üß∞ 1. RAGTool

**Purpose:** Retrieve related pedagogical and content contexts.
**Data Sources:**

* `sgv_collection` (teacher_book)
* `baitap_collection` (textbook)

**Function:**

```python
class RAGTool:
    def retrieve(self, query: str, top_k: int = 5) -> dict:
        return {
            "teacher_context": [...],
            "textbook_context": [...]
        }
```

---

### üìã 2. TemplateTool

**Purpose:** Retrieve question format templates based on subject, grade, and difficulty.

**Function:**

```python
class TemplateTool:
    def get_template(self, subject: str, grade: int, difficulty: str) -> dict:
        return {
            "type": "multiple_choice",
            "pattern": "{a} + {b} = ?",
            "options": 4
        }
```

---

### ‚úèÔ∏è 3. QuestionGenerationTool

**Purpose:** Generate new question text and answers using retrieved contexts and templates.

**Function:**

```python
class QuestionGenerationTool:
    def generate(self, topic, teacher_context, textbook_context, template, student_profile):
        # Use LLM with generation_prompt.txt
        return question_dict
```

---

### ‚úÖ 4. ValidationTool

**Purpose:** Check and refine the generated question for quality.

**Function:**

```python
class ValidationTool:
    def validate(self, question, teacher_context, textbook_context):
        # Use LLM or rule-based checks
        return {
            "valid": True,
            "validation_status": "approved",
            "feedback": "Question matches content and grade level."
        }
```

---

## üîÅ Workflow Implementation

**File:** `workflow/agent_workflow.py`

```python
class AdaptiveLearningAgent:
    def __init__(self):
        self.rag = RAGTool()
        self.template = TemplateTool()
        self.generator = QuestionGenerationTool()
        self.validator = ValidationTool()

    def run(self, student_profile: dict):
        topic = student_profile["topic"]

        # Step 1: Retrieve contexts
        context = self.rag.retrieve(topic)

        # Step 2: Get question template
        template = self.template.get_template(
            subject=student_profile["subject"],
            grade=student_profile["grade"],
            difficulty=student_profile["difficulty"]
        )

        # Step 3: Generate question
        question = self.generator.generate(
            topic,
            context["teacher_context"],
            context["textbook_context"],
            template,
            student_profile
        )

        # Step 4: Validate
        result = self.validator.validate(
            question,
            context["teacher_context"],
            context["textbook_context"]
        )

        return result
```

---

## üß± Database Integration

| Table / Collection    | Purpose                                            |
| --------------------- | -------------------------------------------------- |
| `sgv_collection`      | Milvus vector DB for teacher_book embeddings       |
| `baitap_collection`   | Milvus vector DB for textbook embeddings           |
| `generated_questions` | Stores generated and validated questions           |
| `validation_logs`     | Keeps track of failed/approved validation attempts |

---

## üåê API Example

**Endpoint:**

```
POST /agent/generate
```

**Request:**

```json
{
  "grade": 1,
  "subject": "To√°n",
  "low_accuracy_skills": ["S5"],
  "topic": "M·∫•y v√† m·∫•y",
  "difficulty": "medium"
}
```

**Response:**

```json
{
  "question": "2 + 3 = m·∫•y?",
  "answers": [
    {"text": "5", "correct": true},
    {"text": "4", "correct": false},
    {"text": "6", "correct": false},
    {"text": "7", "correct": false}
  ],
  "difficulty": "medium",
  "validation_status": "approved"
}
```

---

## ‚öôÔ∏è Technology Stack

| Component              | Technology                |
| ---------------------- | ------------------------- |
| Runtime                | Python                    |
| Workflow Orchestration | LangGraph                 |
| LLM Interface          | Gemini / Ollama           |
| **Embedding Model**    | **dangvantuan/vietnamese-document-embedding** |
| **Embedding Service**  | **database/embeddings/local_embedder.py** |
| VectorDB               | Milvus                    |
| API Server             | FastAPI                   |
| Backend Integration    | FastAPI                   |

---

## üîß Embedding Model Integration

### Existing Component: `database/embeddings/local_embedder.py`

The ALQ-Agent will leverage the existing **Vietnamese Text Embedding Service** which provides:

#### Key Features:
- **Model**: `dangvantuan/vietnamese-document-embedding` (768 dimensions)
- **GPU/CPU**: Automatic detection and optimization
- **Batch Processing**: Parallel processing with configurable workers
- **Memory Management**: CUDA memory optimization and OOM handling
- **Error Handling**: Retry logic with smaller batch sizes

#### Integration in ALQ-Agent:

```python
# agent/models/embedding_model.py
from database.embeddings.local_embedder import LocalEmbedding

class ALQEmbeddingModel:
    def __init__(self):
        self.embedder = LocalEmbedding(
            model_name='dangvantuan/vietnamese-document-embedding',
            batch_size=16,
            verbose=True
        )
    
    def embed_query(self, query: str) -> List[float]:
        """Embed search query for RAG retrieval"""
        return self.embedder.embed_single_text(query)
    
    def embed_contexts(self, contexts: List[str]) -> List[List[float]]:
        """Embed multiple context texts"""
        return self.embedder.embed_texts(contexts)
```

#### Usage in RAGTool:

```python
# agent/tools/rag_tool.py
class RAGTool:
    def __init__(self):
        self.embedding_model = ALQEmbeddingModel()
        self.milvus_client = MilvusClient()
    
    def retrieve(self, query: str, top_k: int = 5) -> dict:
        # Embed the query
        query_embedding = self.embedding_model.embed_query(query)
        
        # Search in both collections
        teacher_results = self.milvus_client.search(
            collection_name="sgv_collection",
            query_vector=query_embedding,
            top_k=top_k
        )
        
        textbook_results = self.milvus_client.search(
            collection_name="baitap_collection", 
            query_vector=query_embedding,
            top_k=top_k
        )
        
        return {
            "teacher_context": teacher_results,
            "textbook_context": textbook_results
        }
```

#### Benefits of Reusing Existing Component:
- ‚úÖ **Proven Vietnamese Language Support**: Optimized for Vietnamese educational content
- ‚úÖ **Production Ready**: Already tested and optimized for the system
- ‚úÖ **Memory Efficient**: Handles large datasets with GPU optimization
- ‚úÖ **Error Resilient**: Built-in retry logic and fallback mechanisms
- ‚úÖ **Consistent Embeddings**: Same model used for both indexing and querying

---

## üß≠ Data Flow Summary

```
Frontend ‚Üí Backend ‚Üí ALQ-Agent
                 ‚Üì
              RAGTool
                 ‚Üì
        {teacher_book, textbook vectorDBs}
                 ‚Üì
         QuestionGenerationTool
                 ‚Üì
            ValidationTool
                 ‚Üì
      Database (store validated question)
                 ‚Üì
          Return JSON result
```

---

## üß© Design Principles

* **Dual-context RAG** ‚Üí Teacher_book (teaching method) + Textbook (content)
* **Adaptive Question Generation** ‚Üí Tailored per student weaknesses
* **Multi-step Validation** ‚Üí Ensures correctness and alignment
* **Traceable Data Flow** ‚Üí Source of each question is logged
* **Modular Tools** ‚Üí Replaceable and upgradable components

---

## ‚úÖ Example Validated Output

```json
{
  "grade": 1,
  "skill": "S5",
  "skill_name": "M·∫•y v√† m·∫•y",
  "subject": "To√°n",
  "question": "2 + 3 = m·∫•y?",
  "answers": [
    {"text": "5", "correct": true},
    {"text": "4", "correct": false},
    {"text": "6", "correct": false},
    {"text": "7", "correct": false}
  ],
  "explaination": "2 c·ªông 3 b·∫±ng 5 theo ph√©p c·ªông c∆° b·∫£n.",
  "difficulty": "medium",
  "validation_status": "approved"
}
```
