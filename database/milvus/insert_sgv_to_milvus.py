#!/usr/bin/env python3
"""
Insert SGV to Milvus - Script nh·∫≠p d·ªØ li·ªáu SGV v√†o Milvus
=========================================================

File n√†y ch·ªãu tr√°ch nhi·ªám nh·∫≠p d·ªØ li·ªáu S√°ch Gi√°o Vi√™n (SGV) v√†o Milvus collection.
ƒê·ªçc file JSON SGV, x·ª≠ l√Ω n·ªôi dung, t·∫°o embeddings v√† l∆∞u v√†o sgv_collection.

Ch·ª©c nƒÉng ch√≠nh:
- ƒê·ªçc file JSON SGV t·ª´ ƒë∆∞·ªùng d·∫´n ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh
- X·ª≠ l√Ω v√† l√†m s·∫°ch n·ªôi dung vƒÉn b·∫£n (s·ª≠a l·ªói OCR, chu·∫©n h√≥a)
- T·∫°o embeddings 768 chi·ªÅu b·∫±ng Vietnamese sentence-transformer
- Nh·∫≠p d·ªØ li·ªáu v√†o collection sgv_collection trong Milvus

S·ª≠ d·ª•ng: python database/milvus/insert_sgv_to_milvus.py
"""

import json
import os
import sys
import re
import traceback
from typing import List, Dict, Any
from tqdm import tqdm

# Ensure project root is on sys.path when running as a script
_CURRENT_DIR = os.path.dirname(__file__)
_PROJECT_ROOT = os.path.abspath(os.path.join(_CURRENT_DIR, '..', '..'))
if _PROJECT_ROOT not in sys.path:
    sys.path.insert(0, _PROJECT_ROOT)

# Local modules (absolute import from project root)
from database.embeddings.local_embedder import LocalEmbedding, EMBEDDING_DIMENSION
from database.milvus.milvus_client import connect, get_collection, insert


MILVUS_ALIAS = "default"
COLLECTION_NAME = "sgv_collection"
DEFAULT_JSON_PATH = os.path.join(
    os.path.dirname(os.path.dirname(__file__)),  # database/
    "data_insert",
    "sgv_ketnoitrithuc.json",
)


def fix_ocr_confused_O_and_0(text: str) -> str:
    text = text.upper()
    text = re.sub(r"\bO(\d+)\b", r"0\1", text)
    text = re.sub(r"(\d)\s+O\s+(\d)", r"\1 0 \2", text)
    text = re.sub(r"([A-Z]{2,})\s+O\b", r"\1 0", text)
    text = re.sub(r"\b([A-Z]{2,})\s+O(\d+)\b", r"\1 0\2", text)
    return re.sub(r"\s+", " ", text.strip())


def normalize_lesson_text(text: str) -> str:
    """
    Chu·∫©n h√≥a text lesson ƒë·ªÉ search t·ªët h∆°n
    """
    if not text:
        return ""
    
    # B∆∞·ªõc 1: Chuy·ªÉn v·ªÅ lowercase
    text = text.lower()
    
    # B∆∞·ªõc 2: Lo·∫°i b·ªè s·ªë ti·∫øt trong ngo·∫∑c
    text = re.sub(r'\(\s*\d+\s*ti·∫øt\s*\)', '', text)
    text = re.sub(r'\(\s*\d+\s*\)', '', text)
    text = re.sub(r'\(\s*ti·∫øt\s*\)', '', text)
    text = re.sub(r'\(\s*\d+ti·∫øt\s*\)', '', text)  # Kh√¥ng c√≥ space
    text = re.sub(r'\(\s*\d+ti·∫øt\)', '', text)  # Kh√¥ng c√≥ space cu·ªëi
    
    # B∆∞·ªõc 3: Lo·∫°i b·ªè "B√†i X." prefix
    text = re.sub(r'^b√†i\s+\d+\.\s*', '', text)
    
    # B∆∞·ªõc 4: Lo·∫°i b·ªè "Ch·ªß ƒë·ªÅ X." prefix  
    text = re.sub(r'^ch·ªß ƒë·ªÅ\s+\d+\.\s*', '', text)
    
    # B∆∞·ªõc 5: Lo·∫°i b·ªè d·∫•u c√¢u th·ª´a
    text = re.sub(r'[^\w\s]', ' ', text)
    
    # B∆∞·ªõc 6: Chu·∫©n h√≥a kho·∫£ng tr·∫Øng
    text = re.sub(r'\s+', ' ', text)
    
    # B∆∞·ªõc 7: Lo·∫°i b·ªè t·ª´ ph·ª•
    stop_words = ['ti·∫øt', 'b√†i', 'ph·∫ßn', 'ch∆∞∆°ng', 'm·ª•c']
    words = text.split()
    words = [word for word in words if word not in stop_words]
    
    return ' '.join(words).strip()


def clean_lesson_title_auto(lesson_parts: List[str]) -> str:
    raw = " ".join(lesson_parts)
    words = re.findall(r"\b[A-Z]+(?:-[A-Z]+)*\b", raw.upper())
    return " ".join(words)


def build_entities_from_item(item: Dict[str, Any]) -> Dict[str, Any]:
    # lesson title
    lesson_parts = item.get("lesson", [])
    lesson_title = " ".join(lesson_parts) if isinstance(lesson_parts, list) else str(lesson_parts)

    # source string
    infor = item.get("infor", {}) or {}
    page = infor.get("page", "") or ""
    source = infor.get("source", "") or ""
    if page != "":
        source = f"{source} - trang {page}" if source else f"trang {page}"

    # collect content from parts
    parts = item.get("parts", []) or []
    all_content: List[str] = []
    front_snippet: List[str] = []

    for idx, part in enumerate(parts):
        topic = part.get("topic", "")
        content = part.get("content", "")

        if topic:
            all_content.append(str(topic))

        if content:
            if isinstance(content, list):
                all_content.extend([str(x) for x in content])
                if idx in [0, 1]:
                    front_snippet.extend([str(x) for x in content])
            else:
                all_content.append(str(content))
                if idx in [0, 1]:
                    front_snippet.append(str(content))

    full_content = "\n\n".join(all_content)

    # text for embedding
    full_content_for_embedding = f"{lesson_title} - {' '.join(front_snippet)}"
    clean_content_for_embedding = fix_ocr_confused_O_and_0(
        clean_lesson_title_auto([full_content_for_embedding])
    )

    # Normalize lesson title for better search
    normalized_lesson = normalize_lesson_text(lesson_title)
    
    return {
        "lesson": lesson_title,
        "normalized_lesson": normalized_lesson,
        "content": full_content,
        "source": source,
        "embed_text": clean_content_for_embedding,
    }


def connect_milvus() -> None:
    connect()


def insert_entities_json(json_path: str = DEFAULT_JSON_PATH) -> None:
    print("üöÄ Inserting SGV data into Milvus")
    print(f"   JSON: {json_path}")
    print(f"   Collection: {COLLECTION_NAME}")

    # Connect
    connect_milvus()

    # Check collection exists by trying to get it
    try:
        get_collection(COLLECTION_NAME)
    except RuntimeError as e:
        raise RuntimeError(f"Collection '{COLLECTION_NAME}' does not exist. Run setup_milvus.py first.")

    # Load JSON
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    # Normalize to list
    if isinstance(data, dict):
        data = [data]

    print(f"üì¶ Loaded {len(data)} items")

    # Build entities and texts for embedding
    print("üîÑ Building entities from items...")
    rows: List[Dict[str, Any]] = [build_entities_from_item(item) for item in tqdm(data, desc="Processing items")]

    # Generate embeddings
    print("üß† Generating embeddings...")
    embedder = LocalEmbedding(verbose=True)
    texts = [row["embed_text"] for row in tqdm(rows, desc="Preparing texts")]
    embeddings = embedder.embed_texts(texts)

    if not embeddings or any(len(vec) != EMBEDDING_DIMENSION for vec in embeddings):
        raise ValueError("Embedding generation failed or wrong dimension")

    # Prepare row-wise data for insert function
    print("üìù Preparing data for insertion...")
    insert_data = []
    for i, (row, embedding) in enumerate(tqdm(zip(rows, embeddings), desc="Preparing data", total=len(rows))):
        insert_data.append({
            "id": f"vector_{i}",
            "lesson": "" if row.get("lesson") is None else str(row.get("lesson")),
            "normalized_lesson": "" if row.get("normalized_lesson") is None else str(row.get("normalized_lesson")),
            "content": "" if row.get("content") is None else str(row.get("content")),
            "source": "" if row.get("source") is None else str(row.get("source")),
            "embedding": embedding
        })

    # Insert using new milvus_client function
    print("üíæ Inserting data into Milvus...")
    insert_result = insert(COLLECTION_NAME, insert_data)

    print(f"‚úÖ Inserted {len(insert_data)} rows. Primary keys: {len(insert_result)}")


def main():
    try:
        json_path = os.environ.get("SGV_JSON_PATH", DEFAULT_JSON_PATH)
        insert_entities_json(json_path)
    except Exception as e:
        print(f"‚ùå Insert failed: {e}")
        traceback.print_exc()


if __name__ == "__main__":
    main()